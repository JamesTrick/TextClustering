{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Cluster Analysis Example"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As guidence for this work, I refer largely to an Email Clustering Thesis https://www.scribd.com/document/21970433/Email-clustering-algorithm, and a pipline referred to in the Wikipedia article on Text Clustering.\n",
    "\n",
    "This notebook starts off by taking example text data and does the following:\n",
    "* Cleans data (Removes stopwords, stems, etc.)\n",
    "* Tokenizes words, might TF-IDF it\n",
    "* Performs Dimension Reduction (PCA algorithm)\n",
    "* Performs Cluster Analysis\n",
    "\n",
    "In this notebook, a number of clustering algorithims are presented such as K-Means, MeanShift, and finally we use a Non-negative Matrix Factorisation technique for topic identification. The purpose of comparing algorithims isn't neccessarily to rule them out, instead it's more about trying to get a working example of each one.\n",
    "\n",
    "For the example dataset used dimension reduction isn't really needed as the size of the dataset is unlikely to be computationally intensive, however it sets the standard for any future use of larger datasets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pprint\n",
    "import nltk\n",
    "\n",
    "from nltk.collocations import *\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.metrics import adjusted_rand_score\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "% matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data used"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For the purposes of this example, we'll just use Sklearn's 20 newsgroups dataset http://scikit-learn.org/stable/datasets/twenty_newsgroups.html#newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_20newsgroups"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "categories = [\n",
    "    'talk.politics.mideast',\n",
    "    'rec.motorcycles',\n",
    "]\n",
    "\n",
    "remove = ('headers', 'footers', 'quotes')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_train = fetch_20newsgroups(subset='train', categories=categories,\n",
    "                               random_state=42,\n",
    "                               remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data_test = fetch_20newsgroups(subset='test', categories=categories,\n",
    "                               random_state=42,\n",
    "                               remove=remove)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[u'\\n\\nYep...I think it\\'s the only CB750 with a 630 chain.\\nAfter 14 years, it\\'s finally stretching into the \"replace\" zone.\\n\\n\\n<Sigh> I know .... I know.',\n",
       " u\": \\n: While you brought up the separate question of Israel's unjustified\\n: policies and practices, I am still unclear about your reaction to\\n: the practices and polocies reflected in the article above.\\n: \\n: Tim\\n\\nNot a separate question Mr. Clock. It is deceiving to judge the \\nresistance movement out of the context of the occupation.\",\n",
       " u'\\n\\n\\tI\\'m not sure that\\'s true.  Let me rephrase; \"You can file a complaint\\n which will bring the person into court.\"  As I understand it, a\\n \"citizens arrest\" does not have to be the physical detention of\\n the person.\\n\\n Better now?',\n",
       " u'\\nI bought my Moto Guzzi from a Univ of Va grad student in Charlottesville\\nlast spring.\\n\\n\\t     Mark Cervi, cervi@oasys.dt.navy.mil, (w) 410-267-2147\\n\\t\\t DoD #0603  MGNOC #12998  \\'87 Moto Guzzi SP-II\\n      \"What kinda bikes that?\" A Moto Guzzi. \"What\\'s that?\" Its Italian.\\n-- ']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = data_train.data\n",
    "train[:4]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data cleaning\n",
    "\n",
    "As we can see from the above, the data given is quite messy and has a formatting, punctuation, stopwords, etc that we'd like to parse out before running our model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>\\n\\nYep...I think it's the only CB750 with a 6...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>: \\n: While you brought up the separate questi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\\n\\n\\tI'm not sure that's true.  Let me rephra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\\nI bought my Moto Guzzi from a Univ of Va gra...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>I was just wondering if there were any law off...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 col\n",
       "0  \\n\\nYep...I think it's the only CB750 with a 6...\n",
       "1  : \\n: While you brought up the separate questi...\n",
       "2  \\n\\n\\tI'm not sure that's true.  Let me rephra...\n",
       "3  \\nI bought my Moto Guzzi from a Univ of Va gra...\n",
       "4  I was just wondering if there were any law off..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({'col':train})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df['col'] = df['col'].str.lower().str.split()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "stop = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['col'] = df['col'].apply(lambda x: [item for item in x if item not in stop])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>col</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>[yep...i, think, it's, cb750, 630, chain., 14,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>[:, :, brought, separate, question, israel's, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>[i'm, sure, that's, true., let, rephrase;, \"yo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>[bought, moto, guzzi, univ, va, grad, student,...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>[wondering, law, officers, read, this., severa...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                 col\n",
       "0  [yep...i, think, it's, cb750, 630, chain., 14,...\n",
       "1  [:, :, brought, separate, question, israel's, ...\n",
       "2  [i'm, sure, that's, true., let, rephrase;, \"yo...\n",
       "3  [bought, moto, guzzi, univ, va, grad, student,...\n",
       "4  [wondering, law, officers, read, this., severa..."
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# df.to_csv('clean_news_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('clean_news_data.csv', usecols=[1],\n",
    "                           names=['text'],\n",
    "                           header=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df = df.dropna()\n",
    "df['text'] = df['text'].str.replace(r'\\W', ' ', case = False)\n",
    "df['text'] = df['text'].str.replace(r'[.,?<>-]', '')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>yep i think its cb750 630 chain 14 years its f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>brought separate question israels unjustif...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>im sure thats true let rephrase  yo file compl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>bought moto guzzi univ va grad student charlot...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>wondering law officers read this several quest...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text\n",
       "0  yep i think its cb750 630 chain 14 years its f...\n",
       "1      brought separate question israels unjustif...\n",
       "2  im sure thats true let rephrase  yo file compl...\n",
       "3  bought moto guzzi univ va grad student charlot...\n",
       "4  wondering law officers read this several quest..."
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = vectorizer.fit_transform(df['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "KMeans(algorithm='auto', copy_x=True, init='k-means++', max_iter=100,\n",
       "    n_clusters=2, n_init=1, n_jobs=1, precompute_distances='auto',\n",
       "    random_state=None, tol=0.0001, verbose=0)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "true_k = 2\n",
    "model = KMeans(n_clusters=true_k, init='k-means++', max_iter=100, n_init=1)\n",
    "model.fit(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top terms per cluster:\n",
      "Cluster 0:  israel  people  jews  armenian  israeli  armenians  turkish  would  arab  one\n",
      "Cluster 1:  bike  one  would  its  like  get  know  dont  im  it\n",
      "\n",
      "\n",
      "Prediction\n",
      "[1]\n",
      "[0]\n"
     ]
    }
   ],
   "source": [
    "print(\"Top terms per cluster:\")\n",
    "order_centroids = model.cluster_centers_.argsort()[:, ::-1]\n",
    "terms = vectorizer.get_feature_names()\n",
    "for i in range(true_k):\n",
    "    print(\"Cluster %d:\" % i),\n",
    "    for ind in order_centroids[i, :10]:\n",
    "        print(' %s' % terms[ind]),\n",
    "    print\n",
    "\n",
    "\n",
    "print(\"\\n\")\n",
    "print(\"Prediction\")\n",
    "\n",
    "Y = vectorizer.transform([\"This Motorbike has the best chain\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)\n",
    "\n",
    "Y = vectorizer.transform([\"Turkey is close to Israel\"])\n",
    "prediction = model.predict(Y)\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## MeanShift Clustering\n",
    "\n",
    "MeanShift clustering is another centriod based clustering alogrithim that works in a similar way to the above K-Means. The advantage of Meanshift is that you don't have to specify the number of clusters prior to analysis. This is has a disctinct advantage over K-Means as when analysing general KAs, we're not sure how many natural clusters there are."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import MeanShift, estimate_bandwidth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "bandwidth = estimate_bandwidth(X.toarray(), quantile=0.2, n_samples=500) ## Do PCA or other dimension reduction for real data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mean_shift_model = MeanShift(bin_seeding=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MeanShift(bandwidth=None, bin_seeding=True, cluster_all=True, min_bin_freq=1,\n",
       "     n_jobs=1, seeds=None)"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mean_shift_model.fit(X.toarray())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = mean_shift_model.labels_\n",
    "cluster_centers = mean_shift_model.cluster_centers_\n",
    "\n",
    "labels_unique = np.unique(labels)\n",
    "n_clusters = len(labels_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print n_clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MeanShift at the moment, doesn't look fully helpful if it's only yielding a single cluster... Might need work."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Non-negative Matrix Factorisation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As NMF is typically a dimension reduction technique in itself, the methodology for this algorithim is going to be slightly different. We'll do the following:\n",
    "\n",
    "* Cleans data (Removes stopwords, stems, etc.)\n",
    "* Tokenizes words, might TF-IDF it\n",
    "* Perform NMF on tokenized vector."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
